# Automating Literature Reviews using Deep Learning Methods

Literature reviews play a crucial role in academic research, providing a comprehensive overview of existing knowledge on a particular topic. They are often times carried out at universities and pharmaceutical companiesand require an extensive amount of reading and analysis of scientific publications.

A typical way of conducting a manual literature review consists of several steps.
First, a huge database, such as PubMed, is queried for thousands of studies based on some keywords and basic criteria
that are determined beforehand and describe the given topic.
Next, all titles and abstracts of the returned studies are manually read and a small percentage (3-5 %) is selected
for further review. This is guided by more precise criteria that are too complicated for data base querying.
Finally, a full text review is performed on the remaining studies in order to make sure that only the relevant ones are
included.

However, given the time-consuming nature of reading thousands of abstracts and hundreds of full studies, there is growing interest in automating certain aspects of literature reviews.

In this blog, I will look at the tool Litverse and its approach to partially automating literature reviews with the help of GPT-4 and delve into the inner workings of language models like GPT.

## Litverse
Litverse is a tool that aims at automating literature reviews using several NLP and deep learning methods. Its basic concept is to take preselected papers and a number of criteria and keywords as input and to then output a score and ranking for each paper. The scoring process is split up into two steps - a keyword check and a criteria check.

#### Keyword check
To begin, more specific keywords are manually defined and assigned a priority score ranging from 1 to 3, with 1 being the lowest priority and 3 the highest. This approach ensures that essential concepts required in the literature review are given appropriate weightage.

The next step involves scoring the keywords within each paper. Occurrences of the keywords in the paper's title, abstract, and keyword list are counted and multiplied by their respective priority. This results in a keyword score for each paper that serves as a baseline score for the upcoming clustering step.

To facilitate paper clustering, tf-idf (Term Frequency-Inverse Document Frequency) vectorization is used on the abstracts of all papers. Tf-idf is a popular technique in natural language processing that evaluates the importance of a word in a document relative to its occurrence across all documents. By vectorizing the abstracts, they are converted into numerical representations, allowing for efficient and meaningful comparisons between papers. With the tf-idf vectors in place, the k-means clustering algorithm is employed multiple times with different hyperparapeters to group papers based on their content similarity. The resulting clusters are then ranked using the average keyword score of all papers in the cluster. Finally, the papers are given a clustering score based on how many times they occured in the top two clusters throughout all the iterations of the algorithm.

A given paper has passed the keyword check if it is in top 40% of keyword scores or top 30% of clustering scores. The reason for using both scores for the decision is that papers could be missed by the keyword score if they happen to not include enough of the given keywords but are still relevant to the topic. The clustering score aims at catching those types of papers as they would likely appear in a highly ranked cluster with other relevant papers.

#### Criteria check
Only the papers that passed the keyword check are considered in the criteria check. Here, the criteria that are given to people performing the title and abstract screening in traditional literature reviews, are used in GPT-4 queries. For each paper and criterion, a query looks like this:
```
[title]
[abstract]
[criterion]

Given in percentage, how confident are you that the answer is yes?
```
Taking the average confidence over all criteria, a threshold of 75 % is used to determine whether a paper passes the criteria check.

But how does GPT come up with this percentage? How does it process the raw text input and seemingly magically produce a coherent and sensible response? I will now take this opportunity to take a closer look at language models and explore these questions.

## Language Models
In the age of artificial intelligence and natural language processing, language models have emerged as powerful tools that bridge the gap between human language and machines. One such groundbreaking language model is GPT (Generative Pre-trained Transformer), developed by OpenAI.

At its core, a language model like GPT is designed to predict the probability of the next word or token in a given sequence of text. By analyzing vast amounts of text data during the pre-training phase, the model learns to capture the underlying patterns and relationships between words, allowing it to generate coherent and contextually appropriate responses.

<img width="650" alt="Basic stucture of a language model" src="https://github.com/juliusrichter/juliusrichter.github.io/assets/129942467/d99cb89a-0fa7-42b2-8363-fc02b987cfda">

### Transformers
GPT employs a deep learning architecture known as the Transformer, which efficiently processes and understands the complex dependencies between words in a sequence. Transformer models have had a significant impact on natural language processing (NLP) tasks, such as language translation, text generation, and sentiment analysis. Introduced in the paper "Attention Is All You Need" by Vaswani et al. in 2017, transformers revolutionized the field by addressing the limitations of traditional recurrent neural networks (RNNs) in handling long-range dependencies in sequences.

Transformers are typically designed with an encoder-decoder architecture, commonly used in sequence-to-sequence tasks like machine translation. The encoder processes the input sequence, while the decoder generates the output sequence. This is how a transformer model is usually composed:

<img width="450" alt="Stucture of a transformer" src="https://github.com/juliusrichter/juliusrichter.github.io/assets/129942467/84a6c723-77d5-44dc-91aa-567560cac828">

**Embeddings:**<br>
Any input into the model is first transformed into so called embeddings which map words to continuous, dense vectors in a multi-dimensional space. The main idea behind word embeddings is that words with similar meanings or semantic relationships are mapped to vectors that are closer to each other in the embedding space. For example, words like "dog" and "cat" should have embeddings that are closer together since they are both related to animals.

**Positional encodings:**<br>
Unlike RNNs, transformers do not have a natural sense of sequential order, as they process tokens in parallel. To convey positional information to the model, positional encodings are added to the input embeddings. These encodings represent the relative positions of tokens in the input sequence and enable the model to understand the order of words in the text.

**Self-Attention:**<br>
The key innovation of transformers lies in their self-attention mechanism. This mechanism allows the model to weigh the importance of different words in a sentence concerning a specific word, helping the model focus on relevant information and capture long-range dependencies effectively. Let's look at two exapmple sentences that use different meanings of the word "server":

<p align="center">
"Server, can I have the check?"<br>
"Looks like I just crashed the server."
</p>

In the context of the first sentence, the word "server" refers to a waiter who is being addressed by the speaker at a restaurant. To understand the meaning of "server" in this sentence, the self-attention mechanism would look at the surrounding words in the context and assign weights to each word based on their relevance to the word "server." For example, the word "check" might have a high weight because it is closely related to the waiter's role in delivering the bill. On the other hand, words like "can" and "I" might have lower weights as they are common words that do not directly impact the understanding of the term "server" in this context.

In the second sentence, the word "server" has an entirely different meaning. Here, "server" refers to a computer server. Using self-attention, the transformer model again looks at the surrounding words to understand the context. The word "crashed" would likely have a high weight, as it indicates an issue or problem with the server. Other words like "looks like," "I," and "just" might have lower weights as they don't directly provide essential information about the server.

By employing self-attention on both uses of the word "server" in these sentences, the transformer model can effectively capture the context and meaning of each occurrence, highlighting how this mechanism allows transformers to understand and process language in a highly sophisticated and context-aware manner.

To capture different types of relationships between words, transformers use multi-head attention. They perform self-attention multiple times in parallel, with each self-attention head focusing on different aspects of the input sequence. This allows the model to learn different representations of the input data, capturing various dependencies and patterns.

**Feed-Forward Neural Networks:**<br>
After the self-attention layers, transformers utilize feed-forward neural networks (FFNs) to further process the information. The FFNs consist of fully connected layers and apply element-wise activation functions like ReLU (Rectified Linear Unit). This step introduces non-linearity and allows the model to learn more complex patterns.

**Output:**<br>
The output of a transformer depends on the specific task it is designed to perform. In text generation tasks like a chatbot, the output is usually a sequence of tokens that extend the input text and create a coherent continuation. In translation tasks, the output is  sequence of tokens representing the translated sentence in the target language. Other tasks involve clustering, sentiment analysis and question-answering.


#### Training transformers
Training transformers involves two main phases: pre-training and fine-tuning. During the unsupervised pre-training, the model learns to capture the underlying patterns in a large corpus of text by predicting missing words in sentences (masked language model) and predicting the next word in a sequence (causal language model). The supervised fine-tuning phase, on the other hand, involves training the pre-trained model on specific tasks like classification or question answering. Backpropagation and gradient descent are used in both pre-training and fine-tuning to update the model's parameters during training.

**Masked Language Model (MLM):**<br>
In the masked language model, a percentage of the input tokens in each sentence are randomly masked (replaced with a special [MASK] token). The model is then trained to predict these masked tokens based on the surrounding context. This encourages the model to learn meaningful representations and capture bidirectional context from the left and right of each token. For example, given the sentence "The cat is playing with a ball," the model might see "The cat is [MASK] with a ball." The goal is to predict the masked word (e.g., "playing") based on the context.

**Causal Language Model (CLM):**<br>
In the causal language model, the model is trained to predict the next word in a sequence given the previous words. This is achieved by feeding the input sequence up to the current token and predicting the next token. For example, given the sequence "The cat is playing with a," the model would try to predict the next word "ball." This helps the model learn to capture sequential dependencies and generate coherent text.


## Example review with Litverse
Now that we know how language models using transformers work, let's look at a sample literature review done by Litverse.

For the sample review, 2360 preselected studies were given and the following critera and keywords were set:

<img width="900" alt="Bildschirmfoto 2023-07-05 um 11 08 41" src="https://github.com/juliusrichter/juliusrichter.github.io/assets/129942467/5717fadb-48d6-42d7-87cb-aa54e85cbd0f">

**Keywords:**<br>
<img width="725" alt="Bildschirmfoto 2023-07-05 um 11 25 25" src="https://github.com/juliusrichter/juliusrichter.github.io/assets/129942467/9cbc784a-7b81-4b40-9677-729c54630212">


With all the necessary inputs given, the keyword and criteria checks were be carried out with 43 % of papers passing the keyword check and around 7 % passing both checks and therefore being included in the literature review. In a final overview, all papers are displayed ranked by their criteria score:

<img width="900" alt="Bildschirmfoto 2023-07-05 um 11 10 52" src="https://github.com/juliusrichter/juliusrichter.github.io/assets/129942467/7c78cea3-eb90-4c36-8561-5312323153fe">

Clicking on any paper reveals a more detailed view where the separate criteria scores and the abstract are shown:

<img width="900" alt="Bildschirmfoto 2023-07-31 um 22 20 57" src="https://github.com/juliusrichter/juliusrichter.github.io/assets/129942467/610c2ae4-2a57-4151-9431-a5c7683dd6a2">

As Litverse is still in its early stages, it currently only focuses on the filtering of already given papers which is the most time consuming step in manual literature reviews. However, the selection process is certainly a step that can be automated in the future too.

## Reflection
I will now have a look at a few pros and cons of automated literature reviews and language models in general.

**Pros and cons of automating literature reviews:**<br>
As previously mentioned, tremendous time and resource savings can be achieved by automating the selection and filtering steps of literature reviews. Besides saving time, other benefits of automation include a potentially improved accuracy and objectivity, as human error can be minimized and a difference in approaches by different people is avoided. Additionally, automation tools can efficiently search across various databases and sources, ensuring a more comprehensive coverage of relevant studies that could not be achieved by humans manually querying data bases.

Another important point is that automation makes literature review processes scalable and reproducible. Once an algorithm or tool is developed and validated, it can be applied to various research projects, saving time and resources. Additionally, the ability to reproduce automated analyses ensures transparency and allows for critical evaluation and verification by other researchers.

While automated literature reviews offer several advantages, there are also some potential drawbacks and limitations to consider. Automated approaches may struggle to fully understand the nuanced context and complexity of the literature. They often rely on statistical patterns and keyword matching, which can lead to incomplete interpretations. An example could be a paper that mentions the exact topic of a literature review in one sentence but is not chosen by the model, as it does not contain enough occurences of certain keywords.

Another potential drawback is the inability to detect quality and relevance. Automated approaches might not accurately assess the quality, credibility, or relevance of the literature. Factors such as publication venue, author expertise, and research methodology can significantly impact the reliability and validity of the findings. Automated methods may not be capable of evaluating these aspects effectively, potentially leading to the inclusion of low-quality or irrelevant sources in the review.

Finally, relying solely on automated methods for literature reviews can lead to an overreliance on technology and a potential loss of human expertise and judgment.

**Pros and cons of language models:**<br>
With the emergence of language models and other sophisticated deep learning models come many changes to our everyday life. Language models can assist in content creation, such as generating drafts, writing summaries, or suggesting creative ideas. They can also facilitate real-time translation which is a huge step towards breaking language barriers and enables much more effective communication. Additionally, language models power chatbots like ChatGPT, opening up a completely new way of using the internet to access information.
They models can process and generate text rapidly, providing quick responses to user inputs. They can handle large volumes of data efficiently, making them suitable for applications requiring scalable text processing, such as customer support or information retrieval systems.

However, some big concerns about language models have been raised. They do not have accountability or responsibility for the generated content. As they generate text based on learned patterns, errors, biases, or inappropriate responses may occur without an inherent mechanism for self-correction or responsibility.

Being trained on most of the internet, language models rely on large datasets to learn patterns and generate human-like text. This data often includes user interactions, messages, and personal information. Concerns arise over how this data is collected, stored, and used, as it may involve sensitive or private content. The storage of conversations between users and model has similar problems, as users may unintentionally share sensitive information while interacting with language models.

Lastly, ethical concerns have to be considered when using language models. There are many possibilities for misinformation, deceptive content, or malicious uses. 

## Conclusion
Language models represent a remarkable advancement in natural language processing and artificial intelligence. As we explore the potentials of these sophisticated systems, it becomes evident that they hold the key to transforming our interactions with technology and the way we communicate with the digital world. However, while embracing this groundbreaking technology, we must also acknowledge the need for comprehensive guidelines and ethical frameworks to navigate potential challenges responsibly.

Guidelines will be essential in ensuring that language models are developed and deployed in a manner that prioritizes user privacy, data security, and fairness. Striving for transparency in data usage, anonymization practices, and providing users with control over their information will be crucial steps in building trust between users and these systems. Moreover, continuous efforts to mitigate biases and discriminatory content will be essential to foster an inclusive digital ecosystem that respects diverse perspectives.

Nevertheless, as we address these challenges, we must not lose sight of the vast possibilities that language models open up. From revolutionizing customer support and personalized learning experiences to bridging language barriers and accelerating content creation, their potential for positive impact is immense. These models empower us to reimagine how we interact with technology, sparking creativity, innovation, and transforming various industries.

Whether we like it or not, language models are part of our future and embracing the possibilities that language models offer means taking a step into a future where human-computer interaction is more intuitive, empowering, and efficient. As we tread this path, we must ensure that the advantages they bring do not come at the expense of individual privacy or perpetuating existing societal biases. By striking a balance between innovation and responsible use, we can harness the true potential of language models to make our lives richer, more connected, and collectively prosperous in this digital era. Let us embrace the possibilities they present while upholding our commitment to ethical development, ensuring that these groundbreaking tools serve humanity's best interests.

## References
- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30. https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf
- Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training. https://www.mikecaptain.com/resources/pdf/GPT-1.pdf
- Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large language models are zero-shot reasoners. Advances in neural information processing systems, 35, 22199-22213. https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf
- Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. D. O., Kaplan, J., ... & Zaremba, W. (2021). Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374. https://arxiv.org/pdf/2107.03374.pdf
- Open-AI (2023). GPT-4 Technical Report. https://arxiv.org/pdf/2303.08774.pdf


